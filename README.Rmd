---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# Modelamiento Estad칤stico y Sistemas Recomendadores <img src="img/logo.png" align="right" width = "110px"/>
Repositorio creado para el Trabajo Final del Curso de Modelamiento Estad칤stico y Sistemas Recomendadores en el programa de Diplomado en Big Data para la toma de decisiones de la Pontificia Universidad Cat칩lica de Chile.

**Eduardo Carrasco Vidal**

3/31/2020

<!-- badges: start -->
![R](https://img.shields.io/badge/r-%23276DC3.svg) ![GitHub](https://img.shields.io/badge/github-%23121011.svg)
<!-- badges: end -->

**Requisito: Instalar las siguientes librer칤as**

- _rpart_
- _Hmisc_
- _e1071_
- _rminer_
- _kknn_
- _graphics_
- _factoextra_
- _NbClust_

La versi칩n en desarrollo del documento puede instalarse desde GitHub:

```r
# install.packages("devtools")
# devtools::install_github("educarrascov/DiploBigData")
```

# Trabajo Final:
(**Resumen General**)

En la primera parte del trabajo, se utilizaron 2 modelos de clasificaci칩n (**Naive Bayes / K-NN**), para predecir cifosis en una poblaci칩n dada; para lo cual, se generaron m칠tricas de comparaci칩n (Precisi칩n, Especificidad, Sensibilidad) y una matr칤z de confusi칩n.

En la segunda parte del trabajo; se utiliz칩 un m칠todo de clustering basado en K-means a una muestra obtenida del gasto anual en diferentes productos. 

## I. Parte N췈 1:

Considere la base de datos Kyphosis, inclu칤da en la librer칤a _Rpart_. Esta base de datos contiene datos de **81 ni침os** a los cuales se les realiz칩 una cirug칤a correctiva en la columna vertical y se les midieron las variables descritas en la siguiente tabla:

| variable | descripci칩n|
| ---------| ---------  |
| `Age`    | Edad en meses|
| `Number` | N칰mero de vertebras involucradas|
| `Start`  | N칰mero de la primera V칠rtebra|
|`Kyphosis`| Indica si la persona estudiada presenta (present) o no (absent), la enfermedad denominada cifosis|

Se efectu칩 una simulaci칩n con la estad칤stica descriptiva que involucra aspectos de las 4 variables.

``` {r}
library(rpart) # Cargamos la librer칤a rpart
KyphosisDatos  <-  
kyphosis # Cargamos los datos necesarios para la simulaci칩n
summary(KyphosisDatos) # Resumen de la simulaci칩n.
```
Podemos generar diferentes tablas de cada variables, para efectuar una verificaci칩n inicial.
``` {r}
head(KyphosisDatos) #6 primero datos de todas las variables
```
De igual manera, se puede observar los nombres de cada variable
``` {r}
names(KyphosisDatos)
```
Se genera una tabla para observar los datos de la variable kyphosis.
``` {r}
table(KyphosisDatos$Kyphosis)
```
Se genera una tabla para observar los datos de la variable number.
``` {r}
table(KyphosisDatos$Number) 
```
Se genera una tabla para observar los datos de la variable start.
``` {r}
table(KyphosisDatos$Start)
```

Si se observan los comandos anteriores, podemos ver estad칤sticas descriptivas de las variables como: el n칰mero total de registros corresponde a 11, dentro de los cuales 64 presentan cifosis y 17 no presentan; respecto a los meses, el m칤nimo de mes en que un ni침o presenta esta enfermedad es de 1 y el m치ximo de 206 meses; respecto a la variable n칰mero, el n칰mero de v칠rtebras involucradas tiene un m칤nimo de 2 y un m치ximo de 10; por 칰ltimo, podemos se침alar que la primera v칠rtebra operada en algunos casos es la 1 y en otros la 18.

La funci칩n table(), nos permite visualizar de manera general cada variable de la base de datos pero es m치s usual observar la funci칩n head(), que nos permite observar los 6 primeros valores de cada variable.

Para observar de mejor manera el comportamiento de las variables en un gr치fico de frecuencias, podemos confeccionar un histograma, de acuerdo al siguiente detalle:

``` {r}
par(mfrow=c(1,3)) #permite generar gr치ficos en paralelo, 1 fila por 3 columnas
hist(KyphosisDatos$Age,  main  =  "Histograma  para  Age",  xlab  =  "Age") 
hist(KyphosisDatos$Number,  main  =  "Histograma  para  Number",  xlab  =  "Number")  
hist(KyphosisDatos$Start,  main  =  "Histograma  para  Start",  xlab  =  "Start") 
```

Si realizamos una descipci칩n m치s amplia de las variables utilizando los cuartiles, la mediana y la media aritm칠tica, podemos determinar que la edad promedio de los ni침os corresponde a 83.65 meses. 
Sin embargo, la mayor cantidad de ni침os operados tienen entre uno y dos meses de edad, considerando adem치s que el 25% (1er quartil) de los ni침os estudiados tienen edades hasta los 26 meses, mientras que el 75% (3er quartil) se concentra con edades hasta los 130 meses. Respecto a la variable que involucra el n칰mero de v칠rtebras, el 25% (1er quartil) de los ni침os ha tenido 3 mientras que el 75% (3er quartil) ha tenido hasta 5, con un n칰mero promedio de 4.049, pero siendo 3 v칠rtebras la cantidad m치s frecuente. 

Todo lo anterior se puede identificar gr치ficamente en los histogramas de cada variable.

Por 칰ltimo, aplicamos una funci칩n que permite identificar datos faltantes de acuerdo al siguiente detalle:

``` {r}
library(Hmisc)#cargamos la librer칤a Hmisc 
```
``` {r}
describe(KyphosisDatos) #verificamos que no existen datos faltantes
```
Como se observa en la funci칩n anterior, no hay datos perdidos en ninguna de las variables, por lo cual, podemos finalizar el preprocesamiento de datos.

**1) Seleccione de manera aleatoria 2/3 de los datos para crear sus datos de entrenamiento y guarde el tercio restante para crear los datos de validaci칩n. Utilice la semilla 1 para el generador de n칰meros aleatorios**:

<!-- end list -->
De acuerdo al enunciado, se generan dos bases de datos:

- La primera para entrenamiento correspondiente a 2/3.
- La segunda para prueba correspondiente a 1/3.

Luego, con la siguiente funci칩n observamos la cantidad de valores que se encuentran en los nuevos Data Set.
``` {r}
set.seed(1) #por defecto para generar las distintas bases de datos
ind  <-  sample(2,  length(KyphosisDatos$Kyphosis),  replace=TRUE,  prob=c(2/3, 1/3)) 
#Generamos la divisi칩n de datos en 2/3 y 1/3
table(ind) #cantidad de valores por dataSet
```
Los grupos anteriores se definen de la siguiente forma:

- datos.trabajo.
- datos.validaci칩n.

``` {r}
datos.trabajo  <-  KyphosisDatos[ind==1,] 
datos.validacion  <-  KyphosisDatos[ind==2,] 
```
``` {r}
dim(datos.trabajo) #dimensi칩n del set de trabajo.
```
``` {r}
dim(datos.validacion) #dimensi칩n del set de validaci칩n.
```
**2) Construya un clasificador de *Bayes Ingenuo* para la variable Kyphosis. Realice las predicciones para su clasificador para los datos de validaci칩n:**

<!-- end list -->

``` {r}
library(e1071) #librer칤a sammut and web 2017, clasificadora de naive bayes
fit.NB  <-  naiveBayes(Kyphosis  ~  .,  data=datos.trabajo, laplace = 1) 
#se asigna el clasificador a la var. fit.NB
pred.NB  <-  predict(fit.NB,  datos.validacion[,-1],  type="raw") 
#se realiza una predicci칩n preliminar
```
Con esto observamos la probabilidad de obtener un absent o present, en base a las otras variables, la ventaja que nos da por sobre la funci칩n pred.NB es que esta muestra s칩lo los 6 primeros en la lista.

``` {r}
head(pred.NB)
```
Como lo anterior, no demuestra de manera visual lo correcto o incorrecto que clasifica en modelo seleccionado, s칩lo entrega una probabilidad de ser clasificado como cifosis ausente o presente, lo correcto es aplicar o ejecutar una funci칩n para conocer las m칠tricas, de acuerdo a lo siguiente:

``` {r}
library(rminer) 
#esta funci칩n permite abrir la libreria rminer y poder medir las m칠tricas
mmetric(datos.validacion[,1],  pred.NB,  "ACC") 
#precisi쑕, ref. a Accuracy.
```
``` {r}
mmetric(datos.validacion[,1],  pred.NB,  "TPR") 
#sensibilidad, ref. a True Possitive Rate.
```

``` {r}
mmetric(datos.validacion[,1],  pred.NB,  "TNR") 
#Especificidad, ref. a True Negative Rate.
```
``` {r}
print(pred.NB.Conf  <-  mmetric(datos.validacion[,1],  pred.NB,  "CONF")) 
#permite hacer la matr칤z de confusi칩n
```

``` {r}
print(pred.NB.Conf  <-  mmetric(datos.validacion[,1],  pred.NB,  "AUC"))
#Permite obtener el 치rea bajo la curva ROC (Area Under Curve)
```
Con esta funci칩n podemos incluso obtener una matr칤z de confusi칩n que permite efectuar el c치lculo manual de cada uno de los par치metros anteriormente determinados.
``` {r}
ctable <- as.table(matrix(c(21,1,3,3), nrow = 2, byrow = TRUE)) 
#se deben colocar los valores obtenidos en la matriz
fourfoldplot(ctable, color = c("#CC6666", "#99CC99"),conf.level = 0, margin = 1, main = "Matriz de Confusi칩n - Naive Bayes")
```
Efectuada la confecci칩n de la matriz de confusi칩n y en base a los c칩digos ejecutados, se puede comparar con las verdaderas clases asociadas a cada entrada para as칤 obtener indicadores cuantitativos respecto al desempe침o del modelo.

Para lo anterior, se determinaron las siguientes m칠tricas:

| M칠trica       | Descripci칩n                              |
| ------------  | ------------                             |
| `Precisi칩n`   | (**ACC** - Classification Accuracy Rate) |
| `Sensibilidad`| (**TPR** - True Positive Rate)           |
|`Especificidad`| (**TNR** - True Negative Rate)           |


Si se observan los resultados obtenidos, vemos por un lado que la **`Precisi칩n`** (**ACC - Clasification Accuraccy Rate**) del modelo es de **85.71%**.

Respecto a la variable **`Sensibilidad`** (**TPR - True Possitive Rate**), esta se puede calcular en forma manual de acuerdo a los resultados obtenidos por la matr칤z de confusi칩n, que tiene la siguiente estructura:

<img src="img/matrixcon.png" align="centre" width = "320px"/>

$$ TPR = \frac{TP}{(TP + FP)} $$

$$ TPR = \frac{21}{(21+1)} = 95,45% $$

Respecto a la variable **`Especificidad`** (**TNR - True Negative Rate**), esta se puede calcular en forma manual de acuerdo a los resultados obtenidos por la matr칤z de confusi칩n, que tiene la siguiente estructura:

$$ TNR =\frac{TN}{(TN + FN)} $$

$$ TNR =\frac{3}{(3+3)} = 50,00% $$

De acuerdo a los resultados anteriores, podemos concluir que existe una mayor probabilidad de que el clasificador efect칰e una clasificaci칩n positiva (absent) cuando las variables de entrada tienen caracter칤sticas de positivas (absent), llegando a un 95,45% (sensibilidad), lo cual se puede observar en la matr칤z de confusi칩n. Por otro lado, existe una menor probabilidad de ser clasificado con una clasificaci칩n negativa (present) puesto que de los resultados, no hay realmente una distinci칩n entre los verdaderos negativos y los falsos negativos, lo cual nos
entrega una probabilidad de clasificaci칩n negativa (especificidad) de un 50%.

El marcador global o `Precisi칩n` (**ACC - Classification Accuracy Rate**) del clasificador, se puede determinar por la siguiente formula:

$$ ACC =\frac{(TP + TN)}{(TP + FP + TN + FN)} $$

$$ ACC =\frac{(21 + 3)}{(21 + 1 + 3 + 3)}= 85,71 $$

**3)  Construya un clasificador de *k-vecinos m치s cercanos (KNN)* para la variable Kyphosis. Realice las predicciones para su clasificador para los datos de validaci칩n:**

<!-- end list -->

``` {r}
library(kknn) #cargamos la librer칤a del KNN 
fit.kknn<-kknn(Kyphosis~.,datos.trabajo,datos.validacion,distance= 1,kernel="triangular") 
#efectuamos una predicci칩n utilizando el algoritmo KNN 
```
Como lo anterior, no demuestra de manera visual lo correcto o incorrecto que clasifica en modelo seleccionado, s칩lo entrega una probabilidad de ser clasificado como cifosis ausente (absent) o presente (present), lo correcto es aplicar o ejecutar una funci칩n para conocer las m칠tricas, de acuerdo a lo siguiente:

``` {r}
head(fit.kknn)
```
``` {r}
fit  <-  fitted(fit.kknn) 
#esto lo utilizamos para verificar el desempe침o del ajuste del algoritmo
table(datos.validacion$Kyphosis,fit) 
#con esto verificamos lo ajustado graficamente con una matriz de confusi칩n
```
``` {r}
ctable1 <- as.table(matrix(c(20,2,5,1), nrow = 2, byrow = TRUE)) 
#se deben colocar los valores obtenidos en la matriz
mmetric(datos.validacion$Kyphosis,fit,"ACC")
#Obtenemos la m칠trica, Accuracy, precisi칩n.
```
``` {r}
mmetric(datos.validacion$Kyphosis,fit,"TPR")
```
``` {r}
mmetric(datos.validacion$Kyphosis,fit,"TNR")
```
Con esta funci칩n podemos incluso obtener una matr칤z de confusi칩n que
permite efectuar el c치lculo manual de cada uno de los par치metros
anteriormente determinados:

``` {r}
fourfoldplot(ctable1, color = c("#CC6666", "#99CC99"),conf.level = 0, margin = 1, main = "Matriz de confusi칩n - K-Nearest Neighbors")
```
Efectuada la confecci칩n de la matriz de confusi칩n y en base a los c칩digos ejecutados, se puede comparar con las verdaderas clases asociadas a cada entrada para as칤 obtener indicadores cuantitativos respecto al desempe침o del modelo.

Para lo anterior, se determinaron las siguientes m칠tricas:

| M칠trica       | Descripci칩n                          |
| ------------  | ------------                         |
| `Precisi칩n`   | (ACC - Classification Accuracy Rate) |
| `Sensibilidad`| (TPR - True Positive Rate)           |
|`Especificidad`| (TNR - True Negative Rate)           |

Si se observan los resultados obtenidos, vemos por un lado que la precisi칩n del modelo es de **75,00%**.

Respecto a la variable `Sensibilidad` (**TPR - True Possitive Rate**), esta se puede calcular en forma manual de acuerdo a los resultados obtenidos por la matr칤z de confusi칩n, que tiene la siguiente estructura:

$$ TPR = \frac{20}{(20+2)} = 90,90% $$

Respecto a la variable `Especificidad` (**TNR - True Negative Rate**), esta se puede calcular en forma manual de acuerdo a los resultados obtenidos por la matr칤z de confusi칩n, que tiene la siguiente estructura:

$$ TNR =\frac{1}{(1+5)} = 16,66% $$

De acuerdo a los resultados anteriores, podemos concluir que existe una mayor probabilidad de que el clasificador efect칰e una clasificaci칩n positiva (absent) cuando las variables de entrada tienen caracter칤sticas de positivas (absent), llegando a un **90,90%** (`Sensibilidad`), lo cual se puede observar en la matr칤z de confusi칩n. Por otro lado, existe una probabilidad casi nula de ser clasificado con una clasificaci칩n negativa (present), afectando gravemente al clasificador, lo cual nos entrega una probabilidad de clasificaci칩n negativa (`Especificidad`) de un **16,66%**.

El marcador global o `Precisi칩n` (**ACC - Clasification Accuracy Rate**) del clasificador, se puede determinar por la siguiente formula:

$$ ACC=\frac{(20 + 1)}{(20+ 2 + 1 + 5)}= 75,00% $$

**4)  Compare los clasificadores respecto de su sensibilidad, especificidad y precisi칩n:**

Para efectuar esta comparaci칩n, efectuaremos primero una comparaci칩n entre ambas matrices de confusi칩n:
<!-- end list -->

``` {r}
par(mfrow=c(1,2))
#con esto nos permite generar 1 fila con 2 columnas
fourfoldplot(ctable, color = c("#CC6666", "#99CC99"),conf.level = 0, margin = 1, main = "Naive Bayes", )
fourfoldplot(ctable1, color = c("#CC6666", "#99CC99"),conf.level = 0, margin = 1, main = "K-Nearest Neighbors", )
```
Analizada la matriz de confusi칩n en base a los **TP** y **TN** (c칤rculos verdes), podemos observar que mayoritariamente en la matriz Naive Bayes existe una mayor cantidad de valores positivos (**absent**) que fueron efectivamente determinados por el modelo como valores positivos, por lo cual, la variable `Sensibilidad` (**True Positive Rate**), deber칤a ser m치s grande en Naive Bayes, lo cual se condice con la respuesta obtenida (**95.45 % Naive Bayes / 90.90 % K-NN**). 

Respecto a los valores negativos (**present**) que fueron efectivamente determinados por el modelo como negativo, variable `Especificidad` (**True Negative Rate**), podemos observar que mayoritariamente tambi칠n en el clasificador Naive Bayes, existe una mayor cantidad, lo cual se observa en los valores reales obtenidos (**50.0 Naive Bayes / 16.66 K-NN**).

Por 칰ltimo, podemos se침alar la medida global de efectividad que involucra la suma de ambos valores de predicci칩n correcta (TP, TN) divididos por la suma de todos los valores (TP, TN, FP, FN); que en clasificador Naive Bayes=24 y en el clasificador Knn=21, estos divididos por el total de valores (Test Set) = 28, se obtiene una `Precisi칩n`
(**Classification Accuracy Rate**) mayor para el Naive Bayes (**85.71 % Naive bayes / 75.00 % K-NN**).


## II. Parte N췈 2:

Considere los datos "wholesale.csv", que contiene informaci칩n de 440 clientes de un distribuidor mayorista. La base de datos contiene informaci칩n sobre el gasto anual de cada cliente en productos en las siguientes categor칤as: frescos (fresh), l치cteos (milk), comestibles (grocery), congelados (frozen), detergentes/papel (detergents_paper) y rotiser칤a (delicatessen).

| variable           | descripci칩n                 |
| ------------       | ----------------------      |
| `fresh`            | Productos frescos           |
| `milk`             | Productos lacteos           |
| `Grocery`          | Productos Comestibles       |
| `frozen`           | Productos Congelados        |
| `detergents_paper` | Detergentes y papeles       |
| `delicatessen`     | Productos de Rotiser칤a      |

La estad칤stica descriptiva obtenida a trav칠s del ingreso de c칩digos, se observa en el siguiente cuadro:
``` {r}
Datos_Wholesale<-  read.table("data/wholesale.csv",header=TRUE,  sep=",")
summary(Datos_Wholesale)
```

Podemos observar que no existen datos faltantes en ninguno de los seis atributos, y que estos corresponden a variables num칠ricas que simbolizan el gastos en d칩lares en cada 칤tem.

Al analizar los datos de gastos anuales de los **440 clientes** en las distintas categor칤as se tiene que, a nivel promedio, los `fresh` corresponden a los gastos m치s altos por **12000 USD** mientras que el menor gasto promedio es para los productos de `delicatessen`, donde el monto promedio es de **1524,9 USD**.
Respecto a los m칤nimos, se tiene que 3USD es el gasto m칤nimo realizado en los `fresh`, `Grocery`, `detergents_paper` y `delicatessen`. 
A nivel de m치ximos gastos realizados, se tiene registro de gastos por 112.151 USD en productos catalogados como `fresh` y 92.780 USD para los `Grocery`.
Al revisar los gastos a nivel de cuartiles para los productos, se puede indicar que para los productos frescos que son los con mayor promedio de gastos anuales, se tiene que el **25%** gasta hasta **3.128 USD** y el 75% de los clientes gasta anualmente 16.934 USD. Para el caso de los comestibles, se tiene que el 25% gasta hasta 2.153 USD y el 75% de los clientes gasta anualmente 10.656 USD.
Para el caso de los productos de rotiser칤a que en promedio son los de m치s bajo gasto anual, se tiene que el 25% gasta hasta 408,2 USD y el 75% de los clientes gasta anualmente 1.820 USD.

Cargamos la librer칤a graphics y generamos histogramas de cada variable.
``` {r}
library(graphics) 
par(mfrow=c(2,3))
hist(Datos_Wholesale$Fresh,  main  =  "Hist.Fresh",  xlab  =  "Fresh") 
hist(Datos_Wholesale$Milk,  main  =  "Hist. Milk",  xlab  =  "Milk") 
hist(Datos_Wholesale$Grocery,  main  =  "Hist. Grocery",  xlab  = "Grocery")
hist(Datos_Wholesale$Frozen,  main  =  "Hist. Frozen",  xlab  =  "Frozen") 
hist(Datos_Wholesale$Detergents_Paper,  main  =  "Hist. Detergents_Paper",  xlab  =  "Detergents_Paper")
hist(Datos_Wholesale$Delicassen,  main  =  "Hist. Delicassen",  xlab  = "Delicassen")
```

**a) Utilizando K-means, agrupe las observaciones en k grupos, con k=1,...,10 y determine la suma de las variaciones dentro de cada grupo de k:**

Para realizar los agrupamientos o segmentaciones (generar cl칰ster), se usar치 la funci칩n kmeans () donde 洧녲 es el n칰mero de clusters fijado, estos simbolizan que los objetos pertenecientes a cada grupo (cl칰ster), est칠n relacionados de mejor manera entre s칤, comparados con objetos asignados en otros grupos. 

``` {r}
D1=kmeans(Datos_Wholesale, 1)
D2=kmeans(Datos_Wholesale, 2)
D3=kmeans(Datos_Wholesale, 3)
D4=kmeans(Datos_Wholesale, 4)
D5=kmeans(Datos_Wholesale, 5)
D6=kmeans(Datos_Wholesale, 6)
D7=kmeans(Datos_Wholesale, 7)
D8=kmeans(Datos_Wholesale, 8)
D9=kmeans(Datos_Wholesale, 9)
D10=kmeans(Datos_Wholesale, 10)
```

Una vez generados los segmentos o grupos, desde el D1 al D10 que simbolizan los k=1,...,10, podemos obtener las caracter칤sticas de cada uno de ellos mediante los siguientes c칩digos:

``` {r}
D1$withinss
D1$size
D2$withinss
D2$size
D3$withinss
D3$size
D4$withinss
D4$size
D5$withinss
D5$size
D6$withinss
D6$size
D7$withinss
D7$size
D8$withinss
D8$size
D9$withinss
D9$size
D10$withinss
D10$size
```
Podemos visualizar gr치ficamente los cl칰sters usando la funci칩n fviz_cluster() de la librer칤a factoextra. As칤, por ejemplo, para 洧녲 = 3, 洧녲 = 5 y 洧녲 = 9 las gr치ficas son respectivamente las que se muestran abajo.
Estas gr치ficas nos mostrar치n los dos componentes principales (variables m치s significativas), por cada agrupaci칩n.

``` {r}
library(factoextra)
fviz_cluster  (D3,  Datos_Wholesale,  geom  =  "point", 
               stand  =FALSE, ellipse.type =  "Euclid", pointsize = 1.3, 
               labelsize = 15, main = "Ploteo de Cl칰ster en D3", 
               xlab = NULL, ylab = NULL, ggtheme = theme_linedraw())
fviz_cluster  (D5,  Datos_Wholesale,  geom  =  "point", 
               stand  =FALSE, ellipse.type =  "Euclid", pointsize = 1.3, 
               labelsize = 15, main = "Ploteo de Cl칰ster en D5", 
               xlab = NULL, ylab = NULL, ggtheme = theme_linedraw())
fviz_cluster  (D9,  Datos_Wholesale,  geom  =  "point", 
               stand  =FALSE,  ellipse.type =  "Euclid", pointsize = 1.3, 
               labelsize = 15, main = "Ploteo de Cl칰ster en D9", 
               xlab = NULL, ylab = NULL, ggtheme = theme_linedraw())
```

**b)	쮺u치ntos conglomerados utilizar칤a para este conjunto de datos? Justifique su respuesta:**

Para la elecci칩n 칩ptima de un conglomerado, se debe elegir un criterio, este criterio permite identificar el valor 칩ptimo de k, el cual es uno de los mayores problemas al utilizar el m칠todo k-means.
De todos los m칠todos utilizables para identificar este valor, se ha seleccionado el m칠todo elbow (se usa generalmente cuando la mejora es menor a un % del total inicial).

De los c치lculos anteriores, podemos reconocer el whitinss, que simboliza las variaciones, si efectuamos una suma total de las variaciones dentro de cada grupo y conocer sus diferencias, podremos aplicar el m칠todo elbow.


Para obtener el valor de k, lo realizaremos primero por un m칠todo de c치lculo mediante comandos de R y posteriormente mediante un m칠todo gr치fico:

``` {r} 
tots = c(D1$tot.withinss,
         D2$tot.withinss,
         D3$tot.withinss,
         D4$tot.withinss,
         D5$tot.withinss,
         D6$tot.withinss,
         D7$tot.withinss,
         D8$tot.withinss,
         D9$tot.withinss,
         D10$tot.withinss) 
# determinados suma de los cuadrados (Total within-cluster sum of squares).
diferencias = tots[1:9] - tots[2:10]
porcentajes = diferencias/tots[1]
tots
```
En este an치lisis, a partir de 3 clusters la reducci칩n en la suma total de cuadrados internos parece estabilizarse, indicando que K = 3 es una buena opci칩n.

Por otra parte, al aplicar el m칠todo gr치fico y se침alando una l칤nea demarcada en el an치lisis anterior, obtenemos lo siguiente:

``` {r} 
fviz_nbclust  (Datos_Wholesale,  kmeans,  method  =  "wss")  +
geom_vline(xintercept  =  3,  linetype  =  5)  +	labs(subtitle  =  "M칠todo del Codo")
```

En el gr치fico, podemos observar que el inicio del codo se produce justo en **k=3**, lo cual concuerda con lo obtenido anteriormente.

De acuerdo a lo planteado, distintos criterios usados pueden hacer variar el k, en el ejemplo siguiente se muestra la variaci칩n de porcentajes y su incidencia en el k.

``` {r} 
plot(porcentajes)
lines(rep(0.1, 10), type = 'l', col = 'red') # 10 %
lines(rep(0.05, 10), type = 'l', col = 'blue') # 5 %
lines(rep(0.01, 10), type = 'l', col = 'green') # 1 %
```

Dado que cualquier m칠todo que se use no entrega el k 칩ptimo de manera objetiva, se usar치 la funci칩n NbClust(), para determinar cual es el mejor k dentro de un universo de 20 m칠todos, lo cual se realiza en el siguiente cuadro de comandos:

``` {r} 
library("NbClust")
nb  <-  NbClust(Datos_Wholesale,  distance  =  "euclidean",  
                min.nc  =  2,  max.nc  = 10,  method  =  "kmeans")
```
De lo anterior, podemos concluir que de todos los 칤ndices presentados, hay 7 que proponen al k=3 como el valor 칩ptimo. 

Con la siguiente funci칩n se efect칰a la determinaci칩n del 칩ptima en una tabla de frecuencia que combina la relaci칩n de todos los indices. 
``` {r} 
library("factoextra") 
fviz_nbclust(nb)
```

**c)	Realice un gr치fico de dispersi칩n con las variables fresh y grocery, identificando colores y/o figuras, el grupo al que pertenece cada observaci칩n. Comente como se comportan los conglomerados de acuerdo a estas dos variables (Ej: rango de valores, variabilidad, extremos, etc...)**

De acuerdo al resultado anterior, se obtuvo el valor 칩ptimo de k=3, usando este valor, se realizar치 un an치lisis de los atributos Fresh y Grocery, de acuerdo al siguiente c칩digo de ingresos de comando.

``` {r} 
Fresh =  Datos_Wholesale$Fresh 
Grocery  =  Datos_Wholesale$Grocery
plot(Fresh,Grocery,col= c("red",  "blue",  "green")[D3$cluster])
```

De lo anterior, podemos obtener los subgrupos, usando el k=3 por regla del 10%, de acuerdo a lo siguiente:

``` {r} 
# Para obtener subgrupo, usamos k = 3 por regla de 10 %
indices = D3$cluster
subgrupo1 = subset(Datos_Wholesale, indices == 1)
summary(subgrupo1)
dim(subgrupo1)
sd(subgrupo1$Fresh)
sd(subgrupo1$Grocery)
```

De lo anteriormente expuesto (figura y cuadro resumen) se observa que el primer cl칰ster (Rojo), concentrando solo 60 observaciones, se muestra disperso y poco compacto.
Al analizar los productos frescos en el cl칰ster 1, se tiene que el promedio de gastos mensuales es de **30.818 USD**, donde el **gasto m칤nimo registrado es de 22096 USD y el m치ximo es de 112151 USD**. 
Adem치s, se distingue que el 25% de los clientes que adquieren estos productos, gastan hasta 26.294 USD, mientras que el 75% gasta hasta 40.371 USD. 
La _desviaci칩n est치ndar_ obtenida corresponde a **15239.9**, lo que se aleja del promedio de 30818 USD, determinando que es mayor la dispersi칩n de datos.

Al analizar los comestibles en el cl칰ster 1, se tiene que el promedio de gastos mensuales es de 6.289 USD, donde el gasto m칤nimo registrado es de 471USD y el m치ximo es de 20170 USD. Adem치s, se distingue que el 25% de los clientes que adquieren estos productos, gastan hasta 2576 USD, mientras que el 75% gasta hasta 8260 USD. La desviaci칩n est치ndar obtenida corresponde a 4629.03, determinando menor dispersi칩n para este producto en este cl칰ster.

``` {r} 
indices = D3$cluster
subgrupo2 = subset(Datos_Wholesale, indices == 2)
summary(subgrupo2)
dim(subgrupo2)
sd(subgrupo2$Fresh)
sd(subgrupo2$Grocery)
```

Por otro lado, el segundo cl칰ster (azul) es bastante compacto, conteniendo la menor cantidad de observaciones equivalentes a 50.

Al analizar los productos frescos en el cl칰ster 2, se tiene que el promedio de gastos mensuales es de **5407 USD**, donde el **gasto m칤nimo registrado es de 85 USD y el m치ximo es de 44466 USD**. Adem치s, se distingue que el 25% de los clientes que adquieren estos productos, gastan hasta 1764 USD, mientras que el 75% gasta hasta 11088 USD. La _desviaci칩n est치ndar_ obtenida corresponde a **9124.6**, lo que es mayor que el promedio, determinando mayor dispersi칩n para los productos frescos en este cl칰ster.
Al analizar los comestibles en el cl칰ster 2, se tiene que el promedio de gastos mensuales es de 14520 USD, donde el gasto m칤nimo registrado es de 13567 USD y el m치ximo es de 92780 USD. Adem치s, se distingue que el 25% de los clientes que adquieren estos productos, gastan hasta 19808 USD, mientras que el 75% gasta hasta 28970 USD. La desviaci칩n est치ndar obtenida corresponde a 14515.7, lo que es un poco menor que el promedio.

``` {r} 
indices = D3$cluster
subgrupo3 = subset(Datos_Wholesale, indices == 3)
summary(subgrupo3)
dim(subgrupo3)
sd(subgrupo3$Fresh)
sd(subgrupo3$Grocery)
```

Finalmente, el tercer grupo (verde), es el que posee mayor cantidad de observaciones =330.
Al analizar los productos frescos en el cl칰ster 3, se tiene que el promedio de gastos mensuales es de **8253 USD**, donde el **gasto m칤nimo registrado es de 3 USD y el m치ximo es de 22686 USD**. Adem치s, se distingue que el 25% de los clientes que adquieren estos productos, gastan hasta 2867 USD, mientras que el 75% gasta hasta 12372 USD. La _desviaci칩n est치ndar_ obtenida corresponde a **6194.1**, lo que es menor al promedio, determinando menor dispersi칩n para este producto en este cl칰ster.
Al analizar los comestibles en el cl칰ster 3, se tiene que el promedio de gastos mensuales es de 3444 USD, donde el gasto m칤nimo registrado es de 3 USD y el m치ximo es de 22272 USD. Adem치s, se distingue que el 25% de los clientes que adquieren estos productos, gastan hasta 2002  USD,  mientras  que  el  75%  gasta  hasta  7812  USD.   La  desviaci칩n  est치ndar obtenida corresponde a 4370.7, lo que es mayor que el promedio, determinando mayor dispersi칩n para este producto.

## REFERENCIAS:

1.	Horton, Bob (2016) ROC Curves in Two Lines of R Code. Sitio: Revolution Analytics. [en l칤nea] Recuperado de: https://blog.revolutionanalytics.com/2016/08/roc-curves-in-two-lines-of-code.html
2.	Narkhede, Sarang (2018) Understanding AUC - ROC Curve. Sitio Towards Data Science. [en l칤nea] Recuperado de: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
3.	Narkhede, Sarang (2018) Understanding Confusion Matrix. Sitio: Towards Data Science. [en l칤nea] Recuperado de: https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62
4.	Von, Cambridge (2014) FRR, FAR, TPR, FPR, ROC curve, ACC, SPC, PPV, NPV. Sitio: Blog Cambridge [en l칤nea] Recuperado de: https://cambridge-archive.blogspot.com/2014/04/frr-far-tpr-fpr-roc-curve-acc-spc-ppv.html

